{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **All the import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##262335-back\n",
    "##241b2f-sidebar-back\n",
    "import numpy as np\n",
    "import pandas as pd #convert csv data to pandas data set\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as seb #plot the data\n",
    "from sklearn.model_selection import train_test_split #split the data into train and Test\n",
    "from sklearn.linear_model import LogisticRegression #model use to train\n",
    "from sklearn.metrics import accuracy_score #to Check the model accuracy\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Data collection and Procesing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #-load the data in pandas\n",
    "titanic_data = pd.read_csv('E:/class pdf/Machine_Learning/code/titanic/train.csv')\n",
    "titanic_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advance mod Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data['FamilySize'] = titanic_data['SibSp'] + titanic_data['Parch'] + 1  \n",
    "titanic_data.to_csv('E:/class pdf/Machine_Learning/code/titanic/train.csv', index=False) \n",
    "titanic_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data['FamilySize'] = titanic_data['SibSp'] + titanic_data['Parch'] + 1  \n",
    "titanic_data['IsAlone'] = (titanic_data['FamilySize'] == 1).astype(int)\n",
    "titanic_data['AgeClass'] = titanic_data['Age'] * titanic_data['Pclass'] \n",
    "titanic_data.to_csv('E:/class pdf/Machine_Learning/code/titanic/train.csv', index=False) \n",
    "titanic_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "advance mod stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-show the data(full)/ 0 = No, 1 = Yes\n",
    "# pd.options.display.max_rows = titanic_data.shape[0]\n",
    "# titanic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-information about the data set\n",
    "#titanic_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-checking null valus\n",
    "#titanic_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#-fixing the null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-drop the 'Cabin' coloumn due to max null value\n",
    "# titanic_data.drop(columns = 'Cabin', inplace=True)\n",
    "# titanic_data.to_csv('E:/class pdf/Machine_Learning/code/titanic/train.csv', index=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-replace null valu by the mean in age\n",
    "# titanic_data['Age'].fillna(titanic_data['Age'].mean(), inplace=True)\n",
    "# titanic_data.to_csv('E:/class pdf/Machine_Learning/code/titanic/train.csv', index=False) \n",
    "#titanic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#-replace null values with the mode in Embarked\n",
    "#print(titanic_data['Embarked'].mode())\n",
    "# titanic_data['Embarked'] = titanic_data['Embarked'].fillna(titanic_data['Embarked'].mode()[0])\n",
    "# titanic_data.to_csv('E:/class pdf/Machine_Learning/code/titanic/train.csv', index=False) \n",
    "#titanic_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#-drop the coloumn which is not needed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-droping the 'Name' coloumn\n",
    "# titanic_data.drop(columns = ['Name', 'PassengerId', 'Ticket'], inplace=True)\n",
    "# titanic_data.to_csv('E:/class pdf/Machine_Learning/code/titanic/train.csv', index=False) \n",
    "# titanic_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Data Analysis and Plots**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#- total number of people survived 0 = No, 1 = Yes\n",
    "titanic_data[\"Survived\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#titanic_data[\"Sex\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#- plot the total number of people survived\n",
    "seb.countplot(x = 'Survived', data=titanic_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#- Plot of total surviveal Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#- Extended Method data visulization using age\n",
    "Ms = 0\n",
    "Mns = 0\n",
    "for index, row in titanic_data.iterrows():\n",
    "    if row['Survived'] == 0 and row['Age'] <= 18:\n",
    "        Mns += 1\n",
    "    elif row['Survived'] == 1 and row['Age'] >= 18:\n",
    "        Ms+=1    \n",
    "\n",
    "print(Mns, Ms)\n",
    "data = {'Category': ['Survived(1)', 'Not survived(0)'], 'Value': [Ms, Mns]}\n",
    "df = pd.DataFrame(data)\n",
    "seb.barplot(x='Category', y = 'Value', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#- Short Meathod\n",
    "seb.countplot( x = 'IsAlone', hue='Survived', data=titanic_data)\n",
    "titanic_data['IsAlone'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#-Converting *categorical* feature into *numaric* valus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-Sex{m:0, f:1}, Embarked{s:0, c:1, q: 2}\n",
    "# titanic_data.replace({'Sex': {'male': 0, 'female': 1}, 'Embarked': {'S':0, 'Q':1, 'C':2}}, inplace=True)\n",
    "# titanic_data.to_csv('E:/class pdf/Machine_Learning/code/titanic/train.csv', index=False) \n",
    "# titanic_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Separating the *features* and *target* valus**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#- X is features and Y is target valus\n",
    "X = titanic_data[['Pclass', 'Sex', 'Age', 'Fare', 'Embarked', 'IsAlone', 'AgeClass', 'FamilySize']]\n",
    "Y = titanic_data['Survived']\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Spliting the data into *Traing* and *Testing* data**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-divide the data into traing(80%) and testing(20%) data\n",
    "#from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 2)\n",
    "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### **Training And Testing Model With *Logistic Regression***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#- Assing the data to the model here, by default 1st is input features and 2nd is output features...\n",
    "model = LogisticRegression(\n",
    "    C=10,                   \n",
    "    solver='lbfgs',         \n",
    "    class_weight=None,      \n",
    "    max_iter=1000,          \n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#- Model **train** by using **'coefficients' = Learned Patterns for Survival** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#- model is predicting the survial(Y_train) using 'coefficients' from training data(X_train)\n",
    "model_predict_train = model.predict(X_train)\n",
    "print(model_predict_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#-Model accuracy Chaking for **traing** data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-Chaking Accuracy of the model\n",
    "model_accuracy_train = accuracy_score(Y_train, model_predict_train)\n",
    "print(model_accuracy_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#-Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predict_test = model.predict(X_test)\n",
    "print(model_predict_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#-Model testing accuracy  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accuracy_test = accuracy_score(Y_test, model_predict_test)\n",
    "print(model_accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get probabilities and tuned predictions\n",
    "y_probs = model.predict_proba(X_test)[:, 1]  # Survival probabilities\n",
    "y_pred_tuned = (y_probs > 0.4).astype(int)   # Lower threshold to 0.4\n",
    "\n",
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(Y_test, y_pred_tuned)  # <-- This is what you need for the heatmap\n",
    "\n",
    "# Plot\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Reds', \n",
    "            xticklabels=['Predicted: Died', 'Predicted: Survived'], \n",
    "            yticklabels=['Actual: Died', 'Actual: Survived'])\n",
    "plt.title('Confusion Matrix (Threshold = 0.4)')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "params = {\n",
    "    'C': [0.01, 0.1, 1, 10],       \n",
    "    'solver': ['liblinear', 'lbfgs'],\n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "model = GridSearchCV(LogisticRegression(max_iter=1000), params, cv=5)\n",
    "model.fit(X_train, Y_train)\n",
    "print(model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_probs = model.predict_proba(X_test)[:, 1]\n",
    "final_predictions = (y_probs > 0.3).astype(int)\n",
    "print(classification_report(Y_test, final_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100],       \n",
    "    'max_depth': [5],         \n",
    "    'min_samples_split': [2],        \n",
    "    'min_samples_leaf': [1],          \n",
    "    'max_features': ['sqrt'], \n",
    "    'class_weight': ['balanced']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],        \n",
    "    'max_depth': [None, 5, 10, 20],        \n",
    "    'min_samples_split': [2, 5, 10],      \n",
    "    'min_samples_leaf': [1, 2, 4],          \n",
    "    'max_features': ['auto', 'sqrt', 'log2'], \n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,                  \n",
    "    n_jobs=-1,            \n",
    "    scoring='f1',         \n",
    "    verbose=2\n",
    ")\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "cm = confusion_matrix(Y_test, y_pred)\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Not Survived\", \"Survived\"]).plot(cmap='Blues')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred = grid_search.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
